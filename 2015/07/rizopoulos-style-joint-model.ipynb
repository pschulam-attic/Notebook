{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc_zip = ZipFile('data/scleroderma.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LongitudinalSpec(index, date, outcome):\n",
    "    'The index, timestamp, and outcome column names of a longitudinal dataset.'\n",
    "    return {'index': index, 'date': date, 'outcome': outcome}\n",
    "\n",
    "def AlignmentSpec(index, time, date, baseline):\n",
    "    'The date and baseline column names used to align longitudinal data.'\n",
    "    return {'index': index, 'time': time, 'date': date, 'baseline': baseline}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dates(file='tPtData.csv', zipfile=ssc_zip):\n",
    "    with zipfile.open(file) as f:\n",
    "        ptdata = pd.read_csv(f)\n",
    "    dates = ptdata.loc[:, ['PtID', 'DateFirstSeen', 'Date1stSymptom']]\n",
    "    dates['DateFirstSeen'] = pd.to_datetime(dates['DateFirstSeen'])\n",
    "    dates['Date1stSymptom'] = pd.to_datetime(dates['Date1stSymptom'])\n",
    "    dates.columns = ['ptid', 'first_seen', 'first_symptom']\n",
    "    return dates\n",
    "\n",
    "def read_longitudinal(stream, names, renames):\n",
    "    tbl = pd.read_csv(stream).loc[:, [names['index'], names['date'], names['outcome']]]\n",
    "    tbl.columns = [renames['index'], renames['date'], renames['outcome']]\n",
    "    tbl[renames['date']] = pd.to_datetime(tbl[renames['date']])\n",
    "    return tbl[~tbl[renames['outcome']].isnull()]\n",
    "\n",
    "def align_longitudinal(dataset, dates, alignment):\n",
    "    aligned_dataset = pd.merge(dataset, dates, 'left', alignment['index'])\n",
    "    date = aligned_dataset[alignment['date']]\n",
    "    base = aligned_dataset[alignment['baseline']]\n",
    "    aligned_dataset[alignment['time']] = (date - base).dt.days / 365.0\n",
    "    return aligned_dataset[[alignment['index'], alignment['time'], dataset.columns[2]]]\n",
    "\n",
    "def variables(file, zipfile=ssc_zip):\n",
    "    with zipfile.open(file) as f:\n",
    "        tbl = pd.read_csv(f, nrows=1)\n",
    "    return list(tbl.columns)\n",
    "\n",
    "def is_variable(name, file, zipfile=ssc_zip):\n",
    "    with zipfile.open(file) as f:\n",
    "        tbl = pd.read_csv(f, nrows=1)\n",
    "    return name in tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_from_table(index, date, file, zipfile=ssc_zip, **kwargs):\n",
    "    columns = [(k, v) for k, v in kwargs.items() if is_variable(v, file, zipfile)]\n",
    "    if not len(columns) == 1:\n",
    "        raise RuntimeError('Must specify exactly one outcome column.')\n",
    "    else:\n",
    "        rename, outcome = columns[0]\n",
    "    \n",
    "    names = LongitudinalSpec(index, date, outcome)\n",
    "    renames = LongitudinalSpec('ptid', 'date', rename)\n",
    "    \n",
    "    with zipfile.open(file) as f:\n",
    "        tbl = read_longitudinal(f, names, renames)\n",
    "        \n",
    "    return tbl\n",
    "\n",
    "def read_from_visits(zipfile=ssc_zip, **kwargs):\n",
    "    return read_from_table('PtID', 'Visit.Date', 'tVisit.csv', zipfile, **kwargs)\n",
    "\n",
    "def read_from_echos(zipfile=ssc_zip, **kwargs):\n",
    "    return read_from_table('PtID', 'Date.of.ECHO', 'tECHO.csv', zipfile, **kwargs)\n",
    "\n",
    "def read_from_pfts(zipfile=ssc_zip, **kwargs):\n",
    "    return read_from_table('PtID', 'Date', 'tPFT.csv', zipfile, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = read_dates()\n",
    "alignment = AlignmentSpec('ptid', 'years_seen', 'date', 'first_seen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rp_ss = align_longitudinal(read_from_visits(rp='RP.Sev.Score'), dates, alignment)\n",
    "heart_ss = align_longitudinal(read_from_visits(heart='Heart.Sev.Score'), dates, alignment)\n",
    "gen_ss = align_longitudinal(read_from_visits(general='lkpGeneralScore'), dates, alignment)\n",
    "kidney_ss = align_longitudinal(read_from_visits(kidney='lkpLabUrineProtein'), dates, alignment)\n",
    "muscle_ss = align_longitudinal(read_from_visits(muscle='Muscle.Sev.Score'), dates, alignment)\n",
    "gi_ss = align_longitudinal(read_from_visits(gi='GI.Sev.Score'), dates, alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rvsp = align_longitudinal(read_from_echos(rvsp='RVSP'), dates, alignment)\n",
    "ejection_frac = align_longitudinal(read_from_echos(ef='Ejection.Fraction'), dates, alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pfev1 = align_longitudinal(read_from_pfts(pfev1='perc.FEV1.of.predicted'), dates, alignment)\n",
    "pdlco = align_longitudinal(read_from_pfts(pdlco='perc.DLCO.of.predicted'), dates, alignment)\n",
    "pfev1fvc = align_longitudinal(read_from_pfts(pfev1fvc='perc.FEV1FVC.of.predicted'), dates, alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm_pfvc = pd.read_csv('data/benchmark_pfvc.csv').loc[:, ['ptid', 'years_seen_full', 'pfvc']]\n",
    "bm_pfvc.columns = ['ptid', 'years_seen', 'pfvc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bm_ptid = set(bm_pfvc['ptid'].values)\n",
    "def select_bm(tbl, ptids=bm_ptid):\n",
    "    tbl = tbl[[ptid in ptids for ptid in tbl['ptid']]]\n",
    "    tbl = tbl[tbl['years_seen'] >= 0.0]\n",
    "    return tbl.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aux_names   = ['rp',  'hrt',    'gen',  'kid',     'msc',     'gi',  'sp', 'ef',         'pv1', 'pdc' ]\n",
    "aux_markers = [rp_ss, heart_ss, gen_ss, kidney_ss, muscle_ss, gi_ss, rvsp, ejection_frac, pfev1, pdlco]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm_auxm = [select_bm(m) for m in aux_markers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict, LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def fit_mlm(data):\n",
    "    outcome = str(data.columns[2])\n",
    "    formula = '{} ~ years_seen'.format(outcome)\n",
    "    model   = smf.mixedlm(formula, data, re_formula='years_seen', groups=data['ptid'])\n",
    "    fitted  = model.fit(reml=False)\n",
    "    return fitted\n",
    "\n",
    "def add_mlm_features(subtypes, mlm, prefix):\n",
    "    intercept, slope = mlm.fe_params\n",
    "    ranef = mlm.random_effects\n",
    "    ranef.columns = ['{}_{}'.format(prefix, n) for n in ('intercept', 'slope')]\n",
    "    subtypes = pd.merge(subtypes, ranef, 'left', left_index=True, right_index=True)\n",
    "    subtypes[ranef.columns[0]].fillna(intercept, inplace=True)\n",
    "    subtypes[ranef.columns[1]].fillna(slope, inplace=True)\n",
    "    return subtypes\n",
    "\n",
    "def add_val_features(subtypes, mlm, prefix, time):\n",
    "    intercept, slope = mlm.fe_params\n",
    "    ranef = mlm.random_effects\n",
    "    ranef.columns = ['{}_{}'.format(prefix, n) for n in ('intercept', 'slope')]\n",
    "    aligned_ranef = pd.merge(subtypes, ranef, 'left', left_index=True, right_index=True)\n",
    "    intercept = aligned_ranef[ranef.columns[0]].fillna(intercept)\n",
    "    slope = aligned_ranef[ranef.columns[1]].fillna(slope)\n",
    "    subtypes['{}_val'.format(prefix)] = intercept + slope * time\n",
    "    return subtypes\n",
    "\n",
    "def naive_model_score(y):\n",
    "    counts = np.bincount(y)\n",
    "    return (np.argmax(counts) == y).mean()\n",
    "\n",
    "def ability_to_predict(X, y):\n",
    "    par = {'C': list(np.logspace(-4, 2, 10)), 'gamma': list(np.logspace(-2, 1, 10))}\n",
    "    loo = LeaveOneOut(y.size)\n",
    "    clf = GridSearchCV(SVC(class_weight='auto'), par, scoring='accuracy', cv=loo)\n",
    "    return clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtypes = pd.read_csv('benchmark_pfvc_subtypes.csv').set_index('ptid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlm = [fit_mlm(m) for m in bm_auxm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtype_val_features_true_1 = subtypes.copy()\n",
    "for m, n in zip(mlm, aux_names):\n",
    "    subtype_val_features_true_1 = add_val_features(subtype_val_features_true_1, m, n, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtype_val_features_true_2 = subtypes.copy()\n",
    "for m, n in zip(mlm, aux_names):\n",
    "    subtype_val_features_true_2 = add_val_features(subtype_val_features_true_2, m, n, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year 1 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def censor(markers, time):\n",
    "    ix = markers['years_seen'] <= time\n",
    "    return markers[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlm1 = [fit_mlm(censor(m, 1.0)) for m in bm_auxm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = pd.read_csv('benchmark_pfvc_1y_posteriors.csv')\n",
    "P = np.asarray(P.iloc[:, 1:])\n",
    "yhat_posterior = np.argamx(P, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17,   2,   0,   0,   0,   0,   0],\n",
       "       [  4,  93,  22,   6,   0,   1,   0],\n",
       "       [  2,  28, 105,  27,   1,   3,   0],\n",
       "       [  1,   2,  15,  68,  30,  10,   2],\n",
       "       [  0,   3,   6,  22,  82,  20,   6],\n",
       "       [  0,   0,   0,   8,   7,  35,   2],\n",
       "       [  0,   0,   0,   0,   7,   4,  31]])"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = subtypes['subtype'].values - 1\n",
    "confusion_matrix(y, yhat_posterior).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.894736842105\n",
      "0.738095238095\n",
      "0.632530120482\n",
      "0.53125\n",
      "0.589928057554\n",
      "0.673076923077\n",
      "0.738095238095\n"
     ]
    }
   ],
   "source": [
    "for i in range(P.shape[1]):\n",
    "    yi = y[yhat_posterior == i] == i\n",
    "    print(naive_model_score(yi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercept/Slope Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtype_features1 = subtypes.copy()\n",
    "for m, n in zip(mlm1, aux_names):\n",
    "    subtype_features1 = add_mlm_features(subtype_features1, m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = subtype_features1['subtype'].values - 1\n",
    "X = np.asarray(subtype_features1.iloc[:, 1:])\n",
    "X = np.concatenate((X, P), axis=1)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0\n",
      "Starting run 1\n",
      "Starting run 2\n",
      "Starting run 3\n",
      "Starting run 4\n",
      "Starting run 5\n",
      "Starting run 6\n"
     ]
    }
   ],
   "source": [
    "coef_models = []\n",
    "for i in range(P.shape[1]):\n",
    "    print('Starting run {}'.format(i))\n",
    "    Xi = X[yhat_posterior == i]\n",
    "    yi = y[yhat_posterior == i] == i\n",
    "    fi = ability_to_predict(Xi, yi)\n",
    "    coef_models.append(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.738095238095\n",
      "1.0\n",
      "1.0\n",
      "0.647482014388\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for m in coef_models:\n",
    "    print(m.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value at Year 1 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subtype_val_features1 = subtypes.copy()\n",
    "for m, n in zip(mlm1, aux_names):\n",
    "    subtype_val_features1 = add_val_features(subtype_val_features1, m, n, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = subtype_val_features1['subtype'].values - 1\n",
    "X = np.asarray(subtype_val_features1.iloc[:, 1:])\n",
    "X = np.concatenate((X, P), axis=1)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0\n",
      "Starting run 1\n",
      "Starting run 2\n",
      "Starting run 3\n",
      "Starting run 4\n",
      "Starting run 5\n",
      "Starting run 6\n"
     ]
    }
   ],
   "source": [
    "val_models = []\n",
    "for i in range(P.shape[1]):\n",
    "    print('Starting run {}'.format(i))\n",
    "    Xi = X[yhat_posterior == i]\n",
    "    yi = y[yhat_posterior == i] == i\n",
    "    fi = ability_to_predict(Xi, yi)\n",
    "    val_models.append(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.738095238095\n",
      "1.0\n",
      "1.0\n",
      "0.647482014388\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for m in val_models:\n",
    "    print(m.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Year 2 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pschulam/anaconda3/lib/python3.4/site-packages/statsmodels/regression/mixed_linear_model.py:1717: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlm2 = [fit_mlm(censor(m, 2.0)) for m in bm_auxm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = pd.read_csv('benchmark_pfvc_2y_posteriors.csv')\n",
    "P = np.asarray(P.iloc[:, 1:])\n",
    "yhat_posterior = np.argmax(P, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 19,   2,   0,   0,   0,   0,   0],\n",
       "       [  3, 101,  25,   5,   0,   0,   0],\n",
       "       [  1,  23, 111,  19,   0,   2,   0],\n",
       "       [  1,   1,  11,  76,  20,   8,   0],\n",
       "       [  0,   1,   1,  21, 102,   7,   4],\n",
       "       [  0,   0,   0,  10,   2,  52,   1],\n",
       "       [  0,   0,   0,   0,   3,   4,  36]])"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = subtypes['subtype'].values - 1\n",
    "confusion_matrix(y, yhat_posterior).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904761904762\n",
      "0.753731343284\n",
      "0.711538461538\n",
      "0.649572649573\n",
      "0.75\n",
      "0.8\n",
      "0.837209302326\n"
     ]
    }
   ],
   "source": [
    "for i in range(P.shape[1]):\n",
    "    yi = y[yhat_posterior == i] == i\n",
    "    print(naive_model_score(yi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercept/Slope Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtype_features2 = subtypes.copy()\n",
    "for m, n in zip(mlm2, aux_names):\n",
    "    subtype_features2 = add_mlm_features(subtype_features2, m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = subtype_features['subtype'].values - 1\n",
    "X = np.asarray(subtype_features2.iloc[:, 1:])\n",
    "X = np.concatenate((X, P), axis=1)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0\n",
      "Starting run 1\n",
      "Starting run 2\n",
      "Starting run 3\n",
      "Starting run 4\n",
      "Starting run 5\n",
      "Starting run 6\n"
     ]
    }
   ],
   "source": [
    "coef_models2 = []\n",
    "for i in range(P.shape[1]):\n",
    "    print('Starting run {}'.format(i))\n",
    "    Xi = X[yhat_posterior == i]\n",
    "    yi = y[yhat_posterior == i] == i\n",
    "    fi = ability_to_predict(Xi, yi)\n",
    "    coef_models2.append(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904761904762\n",
      "1.0\n",
      "0.711538461538\n",
      "0.709401709402\n",
      "1.0\n",
      "0.861538461538\n",
      "0.976744186047\n"
     ]
    }
   ],
   "source": [
    "for m in coef_models2:\n",
    "    print(m.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value at Year 2 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtype_val_features2 = subtypes.copy()\n",
    "for m, n in zip(mlm2, aux_names):\n",
    "    subtype_val_features2 = add_val_features(subtype_val_features2, m, n, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = subtype_val_features2['subtype'].values - 1\n",
    "X = np.asarray(subtype_val_features2.iloc[:, 1:])\n",
    "X = np.concatenate((X, P), axis=1)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 0\n",
      "Starting run 1\n",
      "Starting run 2\n",
      "Starting run 3\n",
      "Starting run 4\n",
      "Starting run 5\n",
      "Starting run 6\n"
     ]
    }
   ],
   "source": [
    "val_models2 = []\n",
    "for i in range(P.shape[1]):\n",
    "    print('Starting run {}'.format(i))\n",
    "    Xi = X[yhat_posterior == i]\n",
    "    yi = y[yhat_posterior == i] == i\n",
    "    fi = ability_to_predict(Xi, yi)\n",
    "    val_models2.append(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904761904762\n",
      "1.0\n",
      "0.724358974359\n",
      "0.692307692308\n",
      "1.0\n",
      "0.815384615385\n",
      "0.93023255814\n"
     ]
    }
   ],
   "source": [
    "for m in val_models2:\n",
    "    print(m.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
